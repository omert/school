\documentclass[11pt]{article} \usepackage{amssymb}
\usepackage{amsfonts} \usepackage{amsmath} \usepackage{amsthm} \usepackage{bm}
\usepackage{latexsym} \usepackage{epsfig}

\setlength{\textwidth}{6.5 in} \setlength{\textheight}{8.25in}
\setlength{\oddsidemargin}{0in} \setlength{\topmargin}{0in}
\addtolength{\textheight}{.8in} \addtolength{\voffset}{-.5in}

\newtheorem*{theorem*}{Theorem}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem*{lemma*}{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{fact}[theorem]{Fact}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{example}[theorem]{Example}
%\newenvironment{proof}{\noindent \textbf{Proof:}}{$\Box$}

\newcommand{\ignore}[1]{}

\newcommand{\enote}[1]{} \newcommand{\knote}[1]{}
\newcommand{\rnote}[1]{}



% \newcommand{\enote}[1]{{\bf [[Elchanan:} {\emph{#1}}{\bf ]]}}
% \newcommand{\knote}[1]{{\bf [[Krzysztof:} {\emph{#1}}{\bf ]]}}
% \newcommand{\rnote}[1]{{\bf [[Ryan:} {\emph{#1}}{\bf ]]}}



\DeclareMathOperator{\Support}{Supp} \DeclareMathOperator{\Opt}{Opt}
\DeclareMathOperator{\Ordo}{\mathcal{O}}
\newcommand{\MaxkCSP}{\textsc{Max $k$-CSP}}
\newcommand{\MaxkCSPq}{\textsc{Max $k$-CSP$_{q}$}}
\newcommand{\MaxCSP}[1]{\textsc{Max CSP}(#1)} \renewcommand{\Pr}{{\bf
    P}} \renewcommand{\P}{{\bf P}} \newcommand{\Px}{\mathop{\bf P\/}}
\newcommand{\E}{{\bf E}} \newcommand{\Cov}{{\bf Cov}}
\newcommand{\Var}{{\bf Var}} \newcommand{\Varx}{\mathop{\bf Var\/}}

\newcommand{\bits}{\{-1,1\}}

\newcommand{\nsmaja}{\textstyle{\frac{2}{\pi}} \arcsin \rho}

\newcommand{\Inf}{\mathrm{Inf}} \newcommand{\I}{\mathrm{I}}
\newcommand{\J}{\mathrm{J}}

\newcommand{\eps}{\epsilon} \newcommand{\lam}{\lambda}

% \newcommand{\trunc}{\ell_{2,[-1,1]}}
\newcommand{\trunc}{\zeta} \newcommand{\truncprod}{\chi}

\newcommand{\N}{\mathbb N} \newcommand{\R}{\mathbb R}
\newcommand{\Z}{\mathbb Z} \newcommand{\CalE}{{\mathcal{E}}}
\newcommand{\CalC}{{\mathcal{C}}} \newcommand{\CalM}{{\mathcal{M}}}
\newcommand{\CalR}{{\mathcal{R}}} \newcommand{\CalS}{{\mathcal{S}}}
\newcommand{\CalV}{{\mathcal{V}}}
\newcommand{\CalX}{{\boldsymbol{\mathcal{X}}}}
\newcommand{\CalG}{{\boldsymbol{\mathcal{G}}}}
\newcommand{\CalH}{{\boldsymbol{\mathcal{H}}}}
\newcommand{\CalY}{{\boldsymbol{\mathcal{Y}}}}
\newcommand{\CalZ}{{\boldsymbol{\mathcal{Z}}}}
\newcommand{\CalW}{{\boldsymbol{\mathcal{W}}}}
\newcommand{\CalF}{{\mathcal{Z}}}
% \newcommand{\boldG}{{\boldsymbol G}}
% \newcommand{\boldQ}{{\boldsymbol Q}}
% \newcommand{\boldP}{{\boldsymbol P}}
% \newcommand{\boldR}{{\boldsymbol R}}
% \newcommand{\boldS}{{\boldsymbol S}}
% \newcommand{\boldX}{{\boldsymbol X}}
% \newcommand{\boldB}{{\boldsymbol B}}
% \newcommand{\boldY}{{\boldsymbol Y}}
% \newcommand{\boldZ}{{\boldsymbol Z}}
% \newcommand{\boldV}{{\boldsymbol V}}
\newcommand{\boldi}{{\boldsymbol i}} \newcommand{\boldj}{{\boldsymbol
    j}} \newcommand{\boldk}{{\boldsymbol k}}
\newcommand{\boldr}{{\boldsymbol r}}
\newcommand{\boldsigma}{{\boldsymbol \sigma}}
\newcommand{\boldupsilon}{{\boldsymbol \upsilon}}
\newcommand{\hone}{{\boldsymbol{H1}}}
\newcommand{\htwo}{\boldsymbol{H2}}
\newcommand{\hthree}{\boldsymbol{H3}}
\newcommand{\hfour}{\boldsymbol{H4}}


\newcommand{\sgn}{\mathrm{sgn}} \newcommand{\Maj}{\mathrm{Maj}}
\newcommand{\Acyc}{\mathrm{Acyc}}
\newcommand{\UniqMax}{\mathrm{UniqMax}}
\newcommand{\Thr}{\mathrm{Thr}} \newcommand{\littlesum}{{\textstyle
    \sum}}

\newcommand{\half}{{\textstyle \frac12}}
\newcommand{\third}{{\textstyle \frac13}}
\newcommand{\fourth}{{\textstyle \frac14}}

\newcommand{\Stab}{\mathbb{S}}
\newcommand{\StabThr}[2]{\Gamma_{#1}(#2)}
\newcommand{\StabThrmin}[2]{{\underline{\Gamma}}_{#1}(#2)}
\newcommand{\StabThrmax}[2]{{\overline{\Gamma}}_{#1}(#2)}
\newcommand{\TestFcn}{\Psi}

\renewcommand{\phi}{\varphi}

\begin{document}
\title{Information Theory - Exercise 5}

 \author{Omer Tamuz, 035696574}
\maketitle


\begin{enumerate}
\item
Since $E$ depends only on $x$, then $p(x)=Pr(x|E)$ is either zero, if $E$
does not happen for $x$, or $Pr(x)/\alpha=q(x)/\alpha$ if it does. Hence:
  \begin{eqnarray*}
    D(p||q) &=& \sum_xp(x)\log{p(x)\over q(x)}
    \\ &=& \sum_{x\in E}p(x)\log{p(x)\over q(x)}
    \\ &=& \sum_{x\in E}{q(x)\over \alpha}\log{1\over \alpha}
    \\ &=& {-\log \alpha \over \alpha}\sum_{x\in E}q(x)
    \\ &=& {-\log \alpha \over \alpha}\alpha
    \\ &=& -\log \alpha
  \end{eqnarray*}

\item
In the general case
\begin{equation*}
 p(x)=Pr(x|E)={Pr(E|x)Pr(x)\over Pr(E)}={Pr(E|x)q(x)\over \alpha}. 
\end{equation*}
Then:
  \begin{eqnarray*}
    D(p||q) &=& \sum_xp(x)\log{p(x)\over q(x)}
    \\ &=& \sum_xp(x)\log{p(x)\over q(x)}
    \\ &=& \sum_xp(x)\log{Pr(E|x)\over \alpha}
    \\ &\leq& \sum_xp(x)\log{1\over \alpha}
    \\ &=& -\log\alpha\sum_xp(x)
    \\ &=& -\log\alpha
  \end{eqnarray*}
so that $D(p||q)$ is at most $-\log \alpha$.

\item
  \begin{eqnarray*}
    I(X;Y)&=&D(Pr(X,Y)||Pr(X)Pr(Y))
    \\ &=& \sum_{x,y}Pr(x,y)\log{Pr(x,y)\over Pr(x)Pr(y)}
    \\ &=& \sum_{x,y}Pr(x|y)Pr(y)\log{Pr(x|y)Pr(y)\over Pr(x)Pr(y)}
    \\ &=& \sum_{x,y}Pr(x|y)Pr(y)\log{Pr(x|y)\over Pr(x)}
    \\ &=& \sum_xPr(x|y=0)Pr(y=0)\log{Pr(x|y=0)\over Pr(x)}
    \\ &&+\sum_xPr(x|y=1)Pr(y=1)\log{Pr(x|y=1)\over Pr(x)}
    \\ &=& Pr(y=0)\sum_xp_0(x)\log{p_0(x)\over q(x)}
    \\ &&+Pr(y=1)\sum_xp_1(x)\log{p_1(x)\over q(x)}
    \\ &=&Pr(y=0)D(p_0||q)+Pr(y=1)D(p_1||q)
  \end{eqnarray*}
\item
  In this solution I will assume that the programming language with which 
  we're defining Kolmogorov complexity is binary. Therefore, the number 
  of syntactically correct programs of length $n$ is at most $2^n$.

  Given $\delta>0$, let $S_n\subset \{0,1\}^n$ be the set of strings of 
  length $n$ with probability, under $X$, between $H(p,1-p)-\delta$
  and $H(p,1-p)+\delta$. We showed in class 
  (the asymptotic equipartition property) that 
  \begin{enumerate}
  \item 
    \label{setprob}
    the probability of
    this set approaches one for large enough $n$'s, 
  \item
    \label{setsmall}
    that the 
    size of this set, again for large enough $n$'s, is smaller than
    $2^{H(p,1-p)n(1+\delta)}$, 
  \item
    \label{setsize}
    and that the 
    size of this set, again for large enough $n$'s, is larger than
    $2^{H(p,1-p)n(1-2\delta)}$ (this might not have been shown explicitly in class). 
  \end{enumerate}

  Because of (\ref{setsize}), the Kolmogorov complexity of any string
  in $S_n$ is high with probability that approaches one:

  Given a probability $q<1$, let $D$ be such that $1-2^{-D}>q$.
  Given $\zeta>0$, let $\log|S_n|n_0=D/\zeta$.   
  For any $n>n_0$, the number of strings in $S_n$ produced by programs of 
  length less than  $\log|S_n|-D$ is less than the number of such programs, 
  which is less than $2^{\log|S_n|-D}=|S_n|2^{-D}$. 
  Hence, the rest of the strings have complexity
  at least
  \begin{eqnarray*}
    \log|S_n|-D&>&\log|S_n|-\log|S_n|\zeta
    \\ &=&\log|S_n|(1-\zeta)
    \\ &>&H(p,1-p)n(1-2\delta)(1-\zeta).
  \end{eqnarray*}
  There are at least $|S_n|-|S_n|2^{-D}$ 
  such strings, so the probability that $Y$  is among them is
  \begin{equation*}
    {|S_n|-|S_n|2^{-D} \over |S_n|}=1-2^{-D}>q.           
  \end{equation*}
 
  Hence, for any $q<1$ and $\epsilon>0$ there exists an $n_0$ large enough
  so that with probability higher than $q$ the Kolmogorov complexity of
  an element in $S_n$ higher than $H(p,1-p)n(1-2\delta)(1-\zeta)$. 
  Because of (\ref{setprob}), 
  (the probability of a string in $X$ to be in $S$ approaches one), 
  given $\epsilon$, then for $\zeta,\delta>0$ which maintain
  $(1-2\delta)(1-\zeta)=1-\epsilon$, there exists an $n_0$ s.t. 
  for $n>n_0$ the probability
  of a string $X$ to have Kolmogorov complexity greater than 
  $H(p,1-1)n(1-\epsilon)$ is larger than $q$.
  
  Because of (\ref{setsmall}) - $|S_n|<2^{H(p,1-p)n(1+\delta)}$, and because
  the set is obviously enumerable, each element of the set can be calculated
  by a program that enumerates the elements in $S_n$ and stops after
  $O(|S_n|)$ steps. The length of this program would be a constant
  plus $O(\log|S_n|)$, or $O(H(p,1-p)n(1+\delta))$. Hence, the Kolmogorov
  complexity of the strings in $S_n$ is at most $H(p,1-p)n(1+\delta)+C$. Given
  $\epsilon>0$, let $\zeta,\delta>0$ be s.t. $(1+\delta)(1+\zeta)=1+\epsilon$. 
  Then if we choose $n_0$ s.t. $C=H(p,1-p)n_0(1+\delta)\zeta$, then the Kolmogorov
  complexity of a string in $S_n$ is at most $H(p,1-p)n(1+\epsilon)$, 
  and since, again, the probability of $S_n$ goes to one with $n$, 
  the same holds, with high probability, for a string $X$.
  
\end{enumerate}
\end{document}



